{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c710912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Purdue University - Krannert School of Management\n",
    "MS BAIM Program - Summer 2021\n",
    "MGMT-58600-B03 - Python Programming\n",
    "Final Project - Group 6\n",
    "@authors: Su Tien Lee; Chayadeepsai Cherukupalli; Sri Manogna Gurijala; Alejandro Brillembourg Cuenca\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad28317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_recall_curve,precision_score,classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd968f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_exists(file_name):\n",
    "    '''the exists function will accept a string file name and it will check\n",
    "    to see if the file exists or not returning True/False'''\n",
    "    exists = os.path.isfile(file_name)\n",
    "    return exists\n",
    "\n",
    "def create_df(file_name):\n",
    "    '''the create_dataframe function will accept a string file name for a \n",
    "    csv file and it will read the file's contents into a pd data frame'''\n",
    "    dim_df = pd.read_csv(file_name)\n",
    "    print(\"Dataframe file has been created.\\n\")\n",
    "    input(\"Please press 'Enter' to continue.\\n\")\n",
    "    return dim_df\n",
    "\n",
    "def null_check(df):\n",
    "    '''the null_check function accepts a pandas dataframe and displays counts for\n",
    "    null feature values using the .isna() function'''\n",
    "    for i in list(df.columns.values):\n",
    "        print(str(i), \"has\", df[str(i)].isna().sum(), \"null values.\")\n",
    "        print()\n",
    "    input(\"Please press 'Enter' to continue.\\n\")\n",
    "    return df\n",
    "\n",
    "def dup_check(df):\n",
    "    '''the dup_check function accepts a pandas dataframe and displays counts for\n",
    "    duplicate feature values using the .duplicated() function'''\n",
    "    is_dup = df.duplicated()\n",
    "    return is_dup\n",
    "\n",
    "def drop_col(df):\n",
    "    '''the drop_col function will accept a pandas dataframe and it will remove unnecessary columns based\n",
    "    on a user-entered column index'''\n",
    "    done = \"\"\n",
    "    col_to_drop = []\n",
    "    headers = list(df.columns.values)\n",
    "    pp_headers = \"\"\n",
    "    x = 0\n",
    "\n",
    "    for i in headers:\n",
    "        pp_headers += \"- Column item '\" + str(i) + \"' is in index # \" + str(headers.index(i)) +\"\\n\"\n",
    "    print(pp_headers)\n",
    "    \n",
    "    while done.lower() != \"stop\":\n",
    "        done = input(\"Please enter the index of all columns you wish to drop, one at a time. \"\n",
    "                     +\"Once you are done, please enter 'stop': \")\n",
    "        if done.isnumeric() == True and int(done) <= len(headers):\n",
    "            col_to_drop.append(int(done))\n",
    "        elif done.lower() == \"stop\":\n",
    "            continue\n",
    "        else:\n",
    "            print(\"That is not a valid index. Please try again.\")\n",
    "    print(\"\\nCOLUMN(S) DROPPED:\")\n",
    "    print(\"You have successfully dropped the following columns\",col_to_drop,\"\\n\")\n",
    "    df.drop(df.columns[col_to_drop], axis = 'columns', inplace = True)\n",
    "    input(\"Please press 'Enter' to continue.\\n\")\n",
    "    return df\n",
    "\n",
    "def show_shape(df):\n",
    "    '''the show_shape function receives a pandas dataframe and displays the shape of the \n",
    "    dataframe in a string sentence'''\n",
    "    rows, columns = df.shape\n",
    "    print(\"The file contains \" + str(rows) + \" rows and \" + str(columns) + \" columns.\\n\")\n",
    "    input(\"Please press 'Enter' to continue.\\n\")\n",
    "    return None\n",
    "\n",
    "def head_tail(df):\n",
    "    '''the head_tail function receives a pandas dataframe and displays the user-defined \n",
    "    top and bottom rows of a dataframe'''\n",
    "    x = False\n",
    "    while x == False:\n",
    "        rows = input(\"How many rows would you like to review for the top and bottom of the file?: \")\n",
    "        if rows.isnumeric() == True and int(rows) <= df.shape[0]:\n",
    "            rows = int(rows)\n",
    "            print(\"\\nTOP ROWS\")\n",
    "            print(\"See below the top\",rows,\"row(s):\\n\",df.head(rows))\n",
    "            print()\n",
    "            print(\"\\nBOTTOM ROWS\")\n",
    "            print(\"See below the bottom\",rows,\"row(s):\\n\",df.tail(rows))\n",
    "            print()\n",
    "            x = True\n",
    "        else:\n",
    "            print(\"\\nPlease enter a valid number of rows.\")\n",
    "    input(\"Please press 'Enter' to continue.\\n\")\n",
    "    return None\n",
    "\n",
    "def dis_val_count(df):\n",
    "    '''the dis_val_count function accepts a pandas dataframe and displays counts for\n",
    "    all features using the .values() function'''    \n",
    "    for i in list(df.columns.values):\n",
    "        df.sort_values(by = [str(i)])\n",
    "        print(df[str(i)].value_counts())\n",
    "        print()\n",
    "    input(\"Please press 'Enter' to continue.\\n\")\n",
    "    return df\n",
    "\n",
    "def enc_bin(df):\n",
    "    '''the enc_bin function accepts a pandas dataframe and replaces categorical values with binary values'''\n",
    "    df['Gender'] = df['Gender'].replace({'F':1, 'M':0})\n",
    "    df['Attrition_Flag'] = df['Attrition_Flag'].replace({'Existing Customer':1, 'Attrited Customer':0})\n",
    "    return df\n",
    "\n",
    "def enc_ord(df):\n",
    "    '''the enc_ord function accepts a pandas dataframe and replaces categorical values with ordinal values'''\n",
    "    ord_val = {'Card_Category': {'Blue':1, 'Silver':2, 'Gold':3, 'Platinum':4}}\n",
    "    df = df.replace(ord_val)\n",
    "    return df\n",
    "\n",
    "def enc_dum(df):\n",
    "    '''the enc_dum function accepts a pandas dataframe and creates dummy feature values for categorical features'''\n",
    "    df = pd.get_dummies(df, columns = [\"Education_Level\"], prefix = [\"EDU_LVL_\"], drop_first = True) \n",
    "    df = pd.get_dummies(df, columns = [\"Marital_Status\"], prefix = [\"MAR_ST_\"], drop_first = True)\n",
    "    df = pd.get_dummies(df, columns = [\"Income_Category\"], prefix = [\"INC_CAT_\"], drop_first = True)\n",
    "    return df\n",
    "\n",
    "def show_types(df):\n",
    "    '''the show_types function receives a pandas dataframe and displays the data types of the \n",
    "    dataframe in a string sentence'''\n",
    "    for i in list(df.columns.values):\n",
    "        print(\"Column \",str(i),\" contains data of the '\",df[str(i)].dtype,\"' data type.\\n\", sep = \"\")\n",
    "    input(\"Please press 'Enter' to continue.\\n\")\n",
    "    return None\n",
    "\n",
    "def set_X(df):\n",
    "    '''the set_X function receives a pandas dataframe, drops column index 0, and returns remaining data as dataframe'''\n",
    "    X=df.drop(df.columns[0], axis = 'columns')\n",
    "    return X\n",
    "\n",
    "def set_y(df):\n",
    "    '''the set_y function receives a pandas dataframe, sets dataframe to 'Attrition_Flag' only and returns it'''\n",
    "    y=df['Attrition_Flag']\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caa5ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing():\n",
    "    global X_train\n",
    "    '''start program for data preprocessing and model building'''\n",
    "    \n",
    "    # define file name\n",
    "    dim_file = 'Customer-Churn_Dataset.csv'\n",
    "    \n",
    "    # verify that file exists\n",
    "    dim_file_exists = file_exists(dim_file)\n",
    "    \n",
    "    # check if document exists in set path\n",
    "    if dim_file_exists == True:\n",
    "        \n",
    "        # if it does, create data frame and continue\n",
    "        print(\"CREATE FILE:\\n\")\n",
    "        dim_file_df = create_df(dim_file)\n",
    "        \n",
    "        # drop unnecessary columns\n",
    "        print(\"\\nCOLUMN INDEX:\")\n",
    "        dim_file_df = drop_col(dim_file_df)\n",
    "        \n",
    "        # show df rows and columns\n",
    "        print(\"\\nDATAFRAME SHAPE:\")\n",
    "        show_shape(dim_file_df)\n",
    "        \n",
    "        # check for null values\n",
    "        print(\"\\nNULL VALUE CHECK: \\nPlease see below the counts of all null values per feature.\\n\")\n",
    "        null_check(dim_file_df)\n",
    "        \n",
    "        # check for duplicate values\n",
    "        print(\"\\nDUPLICATE VALUE CHECK: \\nPlease see below the result after checking for duplicate rows.\\n\")\n",
    "        print(dup_check(dim_file_df).value_counts())\n",
    "        input(\"Please press 'Enter' to continue.\\n\")  \n",
    "        \n",
    "        # show top and bottom rows of df\n",
    "        print(\"\\nHEAD AND TAIL:\")\n",
    "        head_tail(dim_file_df)\n",
    "        \n",
    "        # display value counts\n",
    "        print(\"\\nVALUE COUNTS PER FEATURE: \\nPlease see below the value counts per all features.\\n\")\n",
    "        dis_val_count(dim_file_df)\n",
    "        print()\n",
    "        \n",
    "        # encode categorical values and show data before and after encoding\n",
    "        print(\"ENCODING CATEGORICAL VALUES: \\n\")\n",
    "        print(\"\\nPlease see below the column data types before categorical encoding.\\n\")        \n",
    "        print(show_types(dim_file_df))                \n",
    "        print(\"Please see below the top 5 rows for column data types before categorical encoding.\")        \n",
    "        print(dim_file_df[['Attrition_Flag','Gender','Card_Category','Education_Level',\n",
    "                           'Marital_Status','Income_Category']].head(5))\n",
    "        dim_file_df = enc_bin(dim_file_df)\n",
    "        print(\"\\nGender and Attrition Flag Categories Encoded Successfully.\\n\")\n",
    "        dim_file_df = enc_ord(dim_file_df)\n",
    "        print(\"\\nCard Category Encoded Successfully.\\n\")\n",
    "        dim_file_df = enc_dum(dim_file_df)\n",
    "        print(\"\\nEducation Level, Marital Status, and Income Categories Encoded Successfully.\\n\")\n",
    "        print(\"Please see below the rows of data after categorical encoding.\")\n",
    "        print(head_tail(dim_file_df))\n",
    "        print(\"\\nPlease see below the column data types after categorical encoding.\\n\")\n",
    "        print(show_types(dim_file_df))\n",
    "        \n",
    "        # define X and y for statistical models\n",
    "        print(\"\\nSTATISTICAL MODEL: \\n\")\n",
    "        df_X = set_X(dim_file_df)\n",
    "        df_y = set_y(dim_file_df)\n",
    "        print(\"X and y axis have been defined for logistic regression and decision tree models.\\n\")\n",
    "        \n",
    "        # split X and y dataframes into test and train data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size = 0.2, random_state = 100)\n",
    "        \n",
    "        # show X and y train and test shapes\n",
    "        print(\"Train and test data has been created with a test dataset of 20% and a train dataset of 80%.\\n\")\n",
    "        print(\"Please see below the shape of each set:\\n\")\n",
    "        print(\"X train data shape:\", X_train.shape)\n",
    "        print(\"y train data shape:\", y_train.shape)\n",
    "        print(\"X test data shape:\", X_test.shape)        \n",
    "        print(\"y test data shape:\", y_test.shape)\n",
    "        input(\"Please press 'Enter' to continue.\\n\")\n",
    "        \n",
    "        # scale datasets\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_scaled_inp = scaler.transform(X_train)\n",
    "        X_scaled_inp_test = scaler.transform(X_test)\n",
    "        print(\"Train and test data has been successfully scaled for logistic regression and decision tree models.\\n\")\n",
    "        \n",
    "        return X_scaled_inp,X_scaled_inp_test, y_train, y_test\n",
    "        \n",
    "    # if file is not found, stop program\n",
    "    else:\n",
    "        print(\"The program will not be able to run as the Microsoft Excel Comma\" +\n",
    "              \"\\nSeparated Values File '\" + dim_file + \"'\\ncannot be found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d04ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the pre_processing function to return the processed dataframes\n",
    "# enter columns 0,21 and 22 for dropping columns followed by 'stop'\n",
    "\n",
    "train_X, test_X, train_y, test_y = pre_processing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638c6438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model #1: logistic regression\n",
    "\n",
    "model_1 = LogisticRegression()\n",
    "model_1.fit(train_X, train_y)\n",
    "y_pred_1 = model_1.predict(test_X)\n",
    "\n",
    "# build model #2: decision tree\n",
    "\n",
    "model_2 = DecisionTreeClassifier(random_state=100)\n",
    "model_2.fit(train_X, train_y)\n",
    "y_pred_2 = model_2.predict(test_X)\n",
    "\n",
    "# build model #3: random forest\n",
    "model_3=RandomForestClassifier(random_state=100)\n",
    "model_3.fit(train_X, train_y)\n",
    "y_pred_3 = model_3.predict(test_X)\n",
    "\n",
    "input(\"models trained press 'Enter' to continue to view results.\\n\")\n",
    "\n",
    "# show accuracy score, confusion matrix, and recall & precision scores \n",
    "\n",
    "# for model_1\n",
    "print(\"\\n Evaluation Metrics for model_1 \\n\")\n",
    "print(\"Accuracy Score:\", \"{:.2%}\".format(accuracy_score(test_y, y_pred_1))) \n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(test_y, y_pred_1))\n",
    "print(\"Recall Score:\", \"{:.2%}\".format(recall_score(test_y, y_pred_1)))\n",
    "print(\"Precision Score:\", \"{:.2%}\".format(precision_score(test_y, y_pred_1)))\n",
    "\n",
    "# for model_2\n",
    "print(\"\\n Evaluation metrics for model_2 \\n\")\n",
    "print(\"Accuracy Score:\", \"{:.2%}\".format(accuracy_score(test_y, y_pred_2)))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(test_y, y_pred_2))\n",
    "print(\"Recall Score:\", \"{:.2%}\".format(recall_score(test_y, y_pred_2)))\n",
    "print(\"Precision Score:\", \"{:.2%}\".format(precision_score(test_y, y_pred_2)))\n",
    "\n",
    "# for model_3\n",
    "print(\"\\n Evaluation metrics for model_3 \\n\")\n",
    "print(\"Accuracy Score:\", \"{:.2%}\".format(accuracy_score(test_y, y_pred_3)))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(test_y, y_pred_3))\n",
    "print(\"Recall Score:\", \"{:.2%}\".format(recall_score(test_y, y_pred_3)))\n",
    "print(\"Precision Score:\", \"{:.2%}\".format(precision_score(test_y, y_pred_3)))\n",
    "\n",
    "# selecting model_3 (random forest) due to better model stats and displaying feature importance\n",
    "print(\"\\nFeature Importance - Random Forest\\n\")\n",
    "plt.figure(figsize=(10,7))\n",
    "feat_importances = pd.Series(model_3.feature_importances_, index = X_train.columns)\n",
    "feat_importances.nlargest(7).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22186f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
